{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32 at 0x1871F2F4E80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open(\"data/train/000c8a36845c0208e833c79c1bffedd1.jpg\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (len(df),) + im.size + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.zeros(shape=shape, dtype=np.float16)\n",
    "for i, file in enumerate(df['id']):\n",
    "    train_images[i] = Image.open('data/train/' + str(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Maynard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Maynard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, MaxPool2D, Flatten\n",
    "from tensorflow.python.keras.layers import BatchNormalization, Activation, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "\n",
    "kernel_size=(3,3)\n",
    "pool_size=(2,2)\n",
    "first_filter=32\n",
    "second_filter=64\n",
    "third_filter=128\n",
    "\n",
    "dropout_conv=0.3\n",
    "dropout_dense=0.3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filter, kernel_size, padding='same', activation='relu', input_shape= (32,32,3)))\n",
    "model.add(Conv2D(first_filter, kernel_size, padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filter, kernel_size, padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(second_filter, kernel_size, padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filter, kernel_size, padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filter, kernel_size, padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(Adam(0.01), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 813,825\n",
      "Trainable params: 812,481\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 3500 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Maynard\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "14000/14000 [==============================] - 10s 713us/sample - loss: 0.2329 - acc: 0.9201 - val_loss: 1.9383 - val_acc: 0.7443\n",
      "Epoch 2/50\n",
      "14000/14000 [==============================] - 6s 408us/sample - loss: 0.0961 - acc: 0.9614 - val_loss: 1.4925 - val_acc: 0.7491\n",
      "Epoch 3/50\n",
      "13952/14000 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9629\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "14000/14000 [==============================] - 6s 416us/sample - loss: 0.0920 - acc: 0.9630 - val_loss: 2.6053 - val_acc: 0.7543\n",
      "Epoch 4/50\n",
      "14000/14000 [==============================] - 6s 412us/sample - loss: 0.0603 - acc: 0.9779 - val_loss: 0.4999 - val_acc: 0.8340\n",
      "Epoch 5/50\n",
      "14000/14000 [==============================] - 6s 409us/sample - loss: 0.0489 - acc: 0.9826 - val_loss: 0.1124 - val_acc: 0.9554\n",
      "Epoch 6/50\n",
      "14000/14000 [==============================] - 6s 414us/sample - loss: 0.0434 - acc: 0.9836 - val_loss: 0.0555 - val_acc: 0.9809\n",
      "Epoch 7/50\n",
      "13824/14000 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9863\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "14000/14000 [==============================] - 6s 407us/sample - loss: 0.0378 - acc: 0.9861 - val_loss: 0.1248 - val_acc: 0.9586\n",
      "Epoch 8/50\n",
      "14000/14000 [==============================] - 6s 410us/sample - loss: 0.0358 - acc: 0.9864 - val_loss: 0.0331 - val_acc: 0.9891\n",
      "Epoch 9/50\n",
      "13952/14000 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9885- ETA\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "14000/14000 [==============================] - 6s 411us/sample - loss: 0.0337 - acc: 0.9885 - val_loss: 0.0346 - val_acc: 0.9877\n",
      "Epoch 10/50\n",
      "14000/14000 [==============================] - 6s 408us/sample - loss: 0.0352 - acc: 0.9869 - val_loss: 0.0314 - val_acc: 0.9891\n",
      "Epoch 11/50\n",
      "14000/14000 [==============================] - 6s 408us/sample - loss: 0.0332 - acc: 0.9886 - val_loss: 0.0311 - val_acc: 0.9903\n",
      "Epoch 12/50\n",
      "14000/14000 [==============================] - 6s 407us/sample - loss: 0.0334 - acc: 0.9884 - val_loss: 0.0310 - val_acc: 0.9894\n",
      "Epoch 13/50\n",
      "13952/14000 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9890- ETA: 4s - loss:\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "14000/14000 [==============================] - 6s 408us/sample - loss: 0.0332 - acc: 0.9891 - val_loss: 0.0311 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "13824/14000 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9888\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "14000/14000 [==============================] - 6s 426us/sample - loss: 0.0322 - acc: 0.9888 - val_loss: 0.0311 - val_acc: 0.9894\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18728991828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)\n",
    "\n",
    "model.fit(x=train_images,\n",
    "          y=df['has_cactus'],\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.zeros(shape=(4000, 32, 32, 3), dtype=np.float16)\n",
    "for i, file in enumerate(test_df['id']):\n",
    "    test_images[i] = Image.open('data/test/' + str(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['has_cactus'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
